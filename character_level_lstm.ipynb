{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T01:59:25.386005Z",
     "start_time": "2020-05-22T01:59:18.373566Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:00:22.720047Z",
     "start_time": "2020-05-22T02:00:22.715011Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../Data/anna_karenina.txt\", \"rb\") as obj:\n",
    "    text = obj.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:00:32.672315Z",
     "start_time": "2020-05-22T02:00:32.663314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Chapter 1\\r\\n\\r\\n\\r\\nHappy families are all alike; every unhappy family is unhappy in its own\\r\\nway.\\r\\n\\r\\nEve'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "Creating two dictionaries:\n",
    "1. int2char -> maps integers to the characters\n",
    "2. char2int -> maps characters to unique integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:08:40.031153Z",
     "start_time": "2020-05-22T02:08:40.000142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 13, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122)\n"
     ]
    }
   ],
   "source": [
    "chars = tuple(set(text))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:08:51.831728Z",
     "start_time": "2020-05-22T02:08:51.827728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 10, 1: 13, 2: 32, 3: 33, 4: 34, 5: 36, 6: 37, 7: 38, 8: 39, 9: 40, 10: 41, 11: 42, 12: 44, 13: 45, 14: 46, 15: 47, 16: 48, 17: 49, 18: 50, 19: 51, 20: 52, 21: 53, 22: 54, 23: 55, 24: 56, 25: 57, 26: 58, 27: 59, 28: 63, 29: 64, 30: 65, 31: 66, 32: 67, 33: 68, 34: 69, 35: 70, 36: 71, 37: 72, 38: 73, 39: 74, 40: 75, 41: 76, 42: 77, 43: 78, 44: 79, 45: 80, 46: 81, 47: 82, 48: 83, 49: 84, 50: 85, 51: 86, 52: 87, 53: 88, 54: 89, 55: 90, 56: 95, 57: 96, 58: 97, 59: 98, 60: 99, 61: 100, 62: 101, 63: 102, 64: 103, 65: 104, 66: 105, 67: 106, 68: 107, 69: 108, 70: 109, 71: 110, 72: 111, 73: 112, 74: 113, 75: 114, 76: 115, 77: 116, 78: 117, 79: 118, 80: 119, 81: 120, 82: 121, 83: 122}\n"
     ]
    }
   ],
   "source": [
    "int2char = dict(enumerate(chars))\n",
    "print(int2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:09:38.257668Z",
     "start_time": "2020-05-22T02:09:38.253700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10: 0, 13: 1, 32: 2, 33: 3, 34: 4, 36: 5, 37: 6, 38: 7, 39: 8, 40: 9, 41: 10, 42: 11, 44: 12, 45: 13, 46: 14, 47: 15, 48: 16, 49: 17, 50: 18, 51: 19, 52: 20, 53: 21, 54: 22, 55: 23, 56: 24, 57: 25, 58: 26, 59: 27, 63: 28, 64: 29, 65: 30, 66: 31, 67: 32, 68: 33, 69: 34, 70: 35, 71: 36, 72: 37, 73: 38, 74: 39, 75: 40, 76: 41, 77: 42, 78: 43, 79: 44, 80: 45, 81: 46, 82: 47, 83: 48, 84: 49, 85: 50, 86: 51, 87: 52, 88: 53, 89: 54, 90: 55, 95: 56, 96: 57, 97: 58, 98: 59, 99: 60, 100: 61, 101: 62, 102: 63, 103: 64, 104: 65, 105: 66, 106: 67, 107: 68, 108: 69, 109: 70, 110: 71, 111: 72, 112: 73, 113: 74, 114: 75, 115: 76, 116: 77, 117: 78, 118: 79, 119: 80, 120: 81, 121: 82, 122: 83}\n"
     ]
    }
   ],
   "source": [
    "char2int = {ch: count for count, ch in int2char.items()}\n",
    "print(char2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:10:11.019914Z",
     "start_time": "2020-05-22T02:10:10.707877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32, 65, 58, 73, 77, 62, 75,  2, 17,  1,  0,  1,  0,  1,  0, 37, 58,\n",
       "       73, 73, 82,  2, 63, 58, 70, 66, 69, 66, 62, 76,  2, 58, 75, 62,  2,\n",
       "       58, 69, 69,  2, 58, 69, 66, 68, 62, 27,  2, 62, 79, 62, 75, 82,  2,\n",
       "       78, 71, 65, 58, 73, 73, 82,  2, 63, 58, 70, 66, 69, 82,  2, 66, 76,\n",
       "        2, 78, 71, 65, 58, 73, 73, 82,  2, 66, 71,  2, 66, 77, 76,  2, 72,\n",
       "       80, 71,  1,  0, 80, 58, 82, 14,  1,  0,  1,  0, 34, 79, 62])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_text = np.array([char2int[ch] for ch in text])\n",
    "encode_text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:15:28.529108Z",
     "start_time": "2020-05-22T02:15:28.524108Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "    # initialize the encoded array\n",
    "    one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
    "    # fill appropriate elements with one\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    # reshape back to original array\n",
    "    one_hot = one_hot.reshape(*arr.shape, n_labels)\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:16:56.361909Z",
     "start_time": "2020-05-22T02:16:56.355912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# test_case\n",
    "\n",
    "test_seq = np.array([1, 2, 3, 4, 5])\n",
    "one_hot = one_hot_encode(test_seq, 10)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:53:57.304384Z",
     "start_time": "2020-05-22T02:53:57.297391Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, batch_size, seq_length):\n",
    "    batch_size_total = batch_size * seq_length\n",
    "    n_batches = len(arr) // batch_size_total\n",
    "    \n",
    "    arr = arr[:n_batches*batch_size_total]\n",
    "    arr = arr.reshape(batch_size, -1)\n",
    "    \n",
    "    for n in range(0, arr.shape[1], seq_length):\n",
    "        x = arr[:, n:n+seq_length]\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T02:57:04.942457Z",
     "start_time": "2020-05-22T02:57:04.936451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = \n",
      " [[32 65 58 73 77 62 75  2 17  1]\n",
      " [ 0 77 65 72 78 64 65 77 76  2]\n",
      " [78 71 64  2 70 58 71 28  4  1]\n",
      " [71 61  2 77 72  2 75 62 77 66]\n",
      " [75 12  2 65 62  2 65 58 61  2]\n",
      " [72  2 61 66 76 60 78 76 76 66]\n",
      " [ 2 33 72 69 69 82 12  2 61 58]\n",
      " [66 71  2 77 65 62  2 60 72 71]] \n",
      "\n",
      "y = \n",
      " [[65 58 73 77 62 75  2 17  1  0]\n",
      " [77 65 72 78 64 65 77 76  2 72]\n",
      " [71 64  2 70 58 71 28  4  1  0]\n",
      " [61  2 77 72  2 75 62 77 66 75]\n",
      " [12  2 65 62  2 65 58 61  2 71]\n",
      " [ 2 61 66 76 60 78 76 76 66 72]\n",
      " [33 72 69 69 82 12  2 61 58 75]\n",
      " [71  2 77 65 62  2 60 72 71 60]]\n"
     ]
    }
   ],
   "source": [
    "# test_case\n",
    "\n",
    "batches = get_batches(encode_text, 8, 50)\n",
    "x, y = next(batches)\n",
    "\n",
    "print(\"x = \\n\", x[:10, :10], \"\\n\")\n",
    "print(\"y = \\n\", y[:10, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T03:03:05.619217Z",
     "start_time": "2020-05-22T03:03:05.616215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Training on GPU.\")\n",
    "else:\n",
    "    print(\"Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T03:44:08.279870Z",
     "start_time": "2020-05-22T03:44:08.269869Z"
    }
   },
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, tokens, n_hidden=256, n_layers=2, drop_prob=0.5, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        # creating character dictionaries\n",
    "        self.chars = tokens\n",
    "        self.int2char = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch: count for count, ch in self.int2char.items()}\n",
    "        # define LSTM\n",
    "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        # define dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        # define final, fully-connected output layer\n",
    "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        r_out, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(r_out)\n",
    "        # stack up LSTM outputs\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        if use_gpu:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T03:44:08.617700Z",
     "start_time": "2020-05-22T03:44:08.603699Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_network(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
    "    net.train()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # create training and validation data\n",
    "    val_idx = int(len(data) * (1 - val_frac))\n",
    "    data, val_data = data[:val_idx], data[val_idx:]\n",
    "    \n",
    "    # train on gpu if available\n",
    "    if use_gpu:\n",
    "        net.cuda()\n",
    "    \n",
    "    counter = 0\n",
    "    n_chars = len(net.chars)\n",
    "    for e in range(epochs):\n",
    "        hidden_state = net.init_hidden(batch_size)\n",
    "        \n",
    "        for x, y in get_batches(data, batch_size, seq_length):\n",
    "            counter += 1\n",
    "            \n",
    "            x = one_hot_encode(x, n_chars)\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            if use_gpu:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "            # new copy of hidden_state\n",
    "            hidden_state = tuple([each.data for each in hidden_state])\n",
    "            \n",
    "            net.zero_grad()\n",
    "            \n",
    "            output, hidden_state = net(inputs, hidden_state)\n",
    "            \n",
    "            # calculate loss and perform backpropagation\n",
    "            loss = criterion(output, targets.view(batch_size * seq_length).long())\n",
    "            loss.backward()\n",
    "            # using clip_grad_norm to avoid exploding gradient problem\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # stats\n",
    "            if counter % print_every == 0:\n",
    "                val_hidden = net.init_hidden(batch_size)\n",
    "                val_losses = []\n",
    "                \n",
    "                net.eval()\n",
    "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
    "                    x = one_hot_encode(x, n_chars)\n",
    "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                    \n",
    "                    val_hidden = tuple([each.data for each in val_hidden])\n",
    "                    \n",
    "                    inputs, targets = x, y\n",
    "                    if use_gpu:\n",
    "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                    \n",
    "                    output, val_hidden = net(inputs, val_hidden)\n",
    "                    val_loss = criterion(output, targets.view(batch_size * seq_length).long())\n",
    "                    val_losses.append(val_loss.item())\n",
    "                \n",
    "                net.train()\n",
    "                \n",
    "                print(\"{}\\n\".format(\"-\" * 50),\n",
    "                      \"Step : {}\\n\".format(counter),\n",
    "                      \"Loss : {}\\n\".format(loss.item()), \n",
    "                      \"Validation Loss : {}\\n\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T03:44:09.468673Z",
     "start_time": "2020-05-22T03:44:09.220222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharRNN(\n",
       "  (lstm): LSTM(84, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=84, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 512\n",
    "n_layers = 2\n",
    "\n",
    "net = CharRNN(chars, n_hidden, n_layers)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T04:27:14.607054Z",
     "start_time": "2020-05-22T03:59:11.680108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Step : 100\n",
      " Loss : 1.5830848217010498\n",
      " Validation Loss : 1.5134381214777628\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 200\n",
      " Loss : 1.5317405462265015\n",
      " Validation Loss : 1.47554456392924\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 300\n",
      " Loss : 1.4878602027893066\n",
      " Validation Loss : 1.440233047803243\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 400\n",
      " Loss : 1.454048752784729\n",
      " Validation Loss : 1.4058611313501994\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 500\n",
      " Loss : 1.4014155864715576\n",
      " Validation Loss : 1.3825571060180664\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 600\n",
      " Loss : 1.3742811679840088\n",
      " Validation Loss : 1.3528647502263387\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 700\n",
      " Loss : 1.3665306568145752\n",
      " Validation Loss : 1.3328427950541177\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 800\n",
      " Loss : 1.3282127380371094\n",
      " Validation Loss : 1.3169770161310832\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 900\n",
      " Loss : 1.2990666627883911\n",
      " Validation Loss : 1.3018500487009683\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 1000\n",
      " Loss : 1.2622883319854736\n",
      " Validation Loss : 1.2955710331598917\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 1100\n",
      " Loss : 1.2886065244674683\n",
      " Validation Loss : 1.289494244257609\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 1200\n",
      " Loss : 1.2555146217346191\n",
      " Validation Loss : 1.268578306833903\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 1300\n",
      " Loss : 1.2457733154296875\n",
      " Validation Loss : 1.2572767972946166\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 1400\n",
      " Loss : 1.2542752027511597\n",
      " Validation Loss : 1.2531721512476603\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 1500\n",
      " Loss : 1.2089931964874268\n",
      " Validation Loss : 1.245591123898824\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 1600\n",
      " Loss : 1.2382301092147827\n",
      " Validation Loss : 1.2367366472880046\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 1700\n",
      " Loss : 1.2338939905166626\n",
      " Validation Loss : 1.2296154975891114\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 1800\n",
      " Loss : 1.1915383338928223\n",
      " Validation Loss : 1.2267102956771851\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 1900\n",
      " Loss : 1.1774176359176636\n",
      " Validation Loss : 1.2213737964630127\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 2000\n",
      " Loss : 1.2022621631622314\n",
      " Validation Loss : 1.215064787864685\n",
      "\n",
      "--------------------------------------------------\n",
      " Step : 2100\n",
      " Loss : 1.1808453798294067\n",
      " Validation Loss : 1.2093878110249838\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-e412d6c7ab8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-41-77f25e975148>\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(net, data, epochs, batch_size, seq_length, lr, clip, val_frac, print_every)\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;31m# using clip_grad_norm to avoid exploding gradient problem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mparam_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mtotal_norm\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mparam_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "seq_length = 100\n",
    "n_epochs = 20\n",
    "\n",
    "train_network(net, encode_text, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
