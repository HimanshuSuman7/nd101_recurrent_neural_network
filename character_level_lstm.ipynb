{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "character_level_lstm.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T01:59:25.386005Z",
          "start_time": "2020-05-22T01:59:18.373566Z"
        },
        "id": "HADi30UP6125",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD7sKy60613D",
        "colab_type": "text"
      },
      "source": [
        "### Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:00:22.720047Z",
          "start_time": "2020-05-22T02:00:22.715011Z"
        },
        "id": "glKxaSIE613E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/anna_karenina.txt\", \"rb\") as obj:\n",
        "    text = obj.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:00:32.672315Z",
          "start_time": "2020-05-22T02:00:32.663314Z"
        },
        "id": "KA4malij613K",
        "colab_type": "code",
        "outputId": "452a2a34-4e47-4199-f5dd-81a8ed6e68fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text[:100]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Chapter 1\\r\\n\\r\\n\\r\\nHappy families are all alike; every unhappy family is unhappy in its own\\r\\nway.\\r\\n\\r\\nEve'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USBqfTcK613Q",
        "colab_type": "text"
      },
      "source": [
        "### Tokenization\n",
        "Creating two dictionaries:\n",
        "1. int2char -> maps integers to the characters\n",
        "2. char2int -> maps characters to unique integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:08:40.031153Z",
          "start_time": "2020-05-22T02:08:40.000142Z"
        },
        "id": "HKG4dwGT613R",
        "colab_type": "code",
        "outputId": "cca995a1-b892-4db4-8ab2-3297e9e50230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "chars = tuple(set(text))\n",
        "print(chars)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 13, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:08:51.831728Z",
          "start_time": "2020-05-22T02:08:51.827728Z"
        },
        "id": "sEjgplDB613X",
        "colab_type": "code",
        "outputId": "7a1bcf80-82e6-4575-ee79-c046efa9e221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "int2char = dict(enumerate(chars))\n",
        "print(int2char)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 10, 1: 13, 2: 32, 3: 33, 4: 34, 5: 36, 6: 37, 7: 38, 8: 39, 9: 40, 10: 41, 11: 42, 12: 44, 13: 45, 14: 46, 15: 47, 16: 48, 17: 49, 18: 50, 19: 51, 20: 52, 21: 53, 22: 54, 23: 55, 24: 56, 25: 57, 26: 58, 27: 59, 28: 63, 29: 64, 30: 65, 31: 66, 32: 67, 33: 68, 34: 69, 35: 70, 36: 71, 37: 72, 38: 73, 39: 74, 40: 75, 41: 76, 42: 77, 43: 78, 44: 79, 45: 80, 46: 81, 47: 82, 48: 83, 49: 84, 50: 85, 51: 86, 52: 87, 53: 88, 54: 89, 55: 90, 56: 95, 57: 96, 58: 97, 59: 98, 60: 99, 61: 100, 62: 101, 63: 102, 64: 103, 65: 104, 66: 105, 67: 106, 68: 107, 69: 108, 70: 109, 71: 110, 72: 111, 73: 112, 74: 113, 75: 114, 76: 115, 77: 116, 78: 117, 79: 118, 80: 119, 81: 120, 82: 121, 83: 122}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:09:38.257668Z",
          "start_time": "2020-05-22T02:09:38.253700Z"
        },
        "id": "uJ3ZOBN8613h",
        "colab_type": "code",
        "outputId": "1b6dc78c-4f18-4356-c481-351268ea3615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "char2int = {ch: count for count, ch in int2char.items()}\n",
        "print(char2int)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{10: 0, 13: 1, 32: 2, 33: 3, 34: 4, 36: 5, 37: 6, 38: 7, 39: 8, 40: 9, 41: 10, 42: 11, 44: 12, 45: 13, 46: 14, 47: 15, 48: 16, 49: 17, 50: 18, 51: 19, 52: 20, 53: 21, 54: 22, 55: 23, 56: 24, 57: 25, 58: 26, 59: 27, 63: 28, 64: 29, 65: 30, 66: 31, 67: 32, 68: 33, 69: 34, 70: 35, 71: 36, 72: 37, 73: 38, 74: 39, 75: 40, 76: 41, 77: 42, 78: 43, 79: 44, 80: 45, 81: 46, 82: 47, 83: 48, 84: 49, 85: 50, 86: 51, 87: 52, 88: 53, 89: 54, 90: 55, 95: 56, 96: 57, 97: 58, 98: 59, 99: 60, 100: 61, 101: 62, 102: 63, 103: 64, 104: 65, 105: 66, 106: 67, 107: 68, 108: 69, 109: 70, 110: 71, 111: 72, 112: 73, 113: 74, 114: 75, 115: 76, 116: 77, 117: 78, 118: 79, 119: 80, 120: 81, 121: 82, 122: 83}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:10:11.019914Z",
          "start_time": "2020-05-22T02:10:10.707877Z"
        },
        "id": "PUZxO1j1613n",
        "colab_type": "code",
        "outputId": "24e204a4-0a36-4a0d-a5c1-6c978b0c165e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "encode_text = np.array([char2int[ch] for ch in text])\n",
        "encode_text[:100]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([32, 65, 58, 73, 77, 62, 75,  2, 17,  1,  0,  1,  0,  1,  0, 37, 58,\n",
              "       73, 73, 82,  2, 63, 58, 70, 66, 69, 66, 62, 76,  2, 58, 75, 62,  2,\n",
              "       58, 69, 69,  2, 58, 69, 66, 68, 62, 27,  2, 62, 79, 62, 75, 82,  2,\n",
              "       78, 71, 65, 58, 73, 73, 82,  2, 63, 58, 70, 66, 69, 82,  2, 66, 76,\n",
              "        2, 78, 71, 65, 58, 73, 73, 82,  2, 66, 71,  2, 66, 77, 76,  2, 72,\n",
              "       80, 71,  1,  0, 80, 58, 82, 14,  1,  0,  1,  0, 34, 79, 62])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUGHBOic613v",
        "colab_type": "text"
      },
      "source": [
        "### Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:15:28.529108Z",
          "start_time": "2020-05-22T02:15:28.524108Z"
        },
        "id": "s0Axk00f613w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_encode(arr, n_labels):\n",
        "    # initialize the encoded array\n",
        "    one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
        "    # fill appropriate elements with one\n",
        "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
        "    # reshape back to original array\n",
        "    one_hot = one_hot.reshape(*arr.shape, n_labels)\n",
        "    \n",
        "    return one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:16:56.361909Z",
          "start_time": "2020-05-22T02:16:56.355912Z"
        },
        "id": "5iKbABcI6131",
        "colab_type": "code",
        "outputId": "96f3dbfe-222c-4091-f821-3f71d6ab38f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# test_case\n",
        "\n",
        "test_seq = np.array([1, 2, 3, 4, 5])\n",
        "one_hot = one_hot_encode(test_seq, 10)\n",
        "print(one_hot)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:53:57.304384Z",
          "start_time": "2020-05-22T02:53:57.297391Z"
        },
        "id": "goG6WVxh6136",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(arr, batch_size, seq_length):\n",
        "    batch_size_total = batch_size * seq_length\n",
        "    n_batches = len(arr) // batch_size_total\n",
        "    \n",
        "    arr = arr[:n_batches*batch_size_total]\n",
        "    arr = arr.reshape(batch_size, -1)\n",
        "    \n",
        "    for n in range(0, arr.shape[1], seq_length):\n",
        "        x = arr[:, n:n+seq_length]\n",
        "        y = np.zeros_like(x)\n",
        "        try:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
        "        except IndexError:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
        "        yield x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:57:04.942457Z",
          "start_time": "2020-05-22T02:57:04.936451Z"
        },
        "id": "2qzvSy1z614A",
        "colab_type": "code",
        "outputId": "eb3dc308-2672-43f0-bd22-ac2cf7af5975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# test_case\n",
        "\n",
        "batches = get_batches(encode_text, 8, 50)\n",
        "x, y = next(batches)\n",
        "\n",
        "print(\"x = \\n\", x[:10, :10], \"\\n\")\n",
        "print(\"y = \\n\", y[:10, :10])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x = \n",
            " [[32 65 58 73 77 62 75  2 17  1]\n",
            " [ 0 77 65 72 78 64 65 77 76  2]\n",
            " [78 71 64  2 70 58 71 28  4  1]\n",
            " [71 61  2 77 72  2 75 62 77 66]\n",
            " [75 12  2 65 62  2 65 58 61  2]\n",
            " [72  2 61 66 76 60 78 76 76 66]\n",
            " [ 2 33 72 69 69 82 12  2 61 58]\n",
            " [66 71  2 77 65 62  2 60 72 71]] \n",
            "\n",
            "y = \n",
            " [[65 58 73 77 62 75  2 17  1  0]\n",
            " [77 65 72 78 64 65 77 76  2 72]\n",
            " [71 64  2 70 58 71 28  4  1  0]\n",
            " [61  2 77 72  2 75 62 77 66 75]\n",
            " [12  2 65 62  2 65 58 61  2 71]\n",
            " [ 2 61 66 76 60 78 76 76 66 72]\n",
            " [33 72 69 69 82 12  2 61 58 75]\n",
            " [71  2 77 65 62  2 60 72 71 60]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJv1scNA614H",
        "colab_type": "text"
      },
      "source": [
        "### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T03:03:05.619217Z",
          "start_time": "2020-05-22T03:03:05.616215Z"
        },
        "id": "hKkSkBNm614I",
        "colab_type": "code",
        "outputId": "2fbcc847-9077-4954-ff5c-2645f4fc6a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    print(\"Training on GPU.\")\n",
        "else:\n",
        "    print(\"Using CPU.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T03:44:08.279870Z",
          "start_time": "2020-05-22T03:44:08.269869Z"
        },
        "id": "zQLOKk7L614P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, tokens, n_hidden=256, n_layers=2, drop_prob=0.5, lr=0.001):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        self.lr = lr\n",
        "        # creating character dictionaries\n",
        "        self.chars = tokens\n",
        "        self.int2char = dict(enumerate(self.chars))\n",
        "        self.char2int = {ch: count for count, ch in self.int2char.items()}\n",
        "        # define LSTM\n",
        "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, dropout=drop_prob, batch_first=True)\n",
        "        # define dropout layer\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        # define final, fully-connected output layer\n",
        "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        r_out, hidden = self.lstm(x, hidden)\n",
        "        out = self.dropout(r_out)\n",
        "        # stack up LSTM outputs\n",
        "        out = out.contiguous().view(-1, self.n_hidden)\n",
        "        out = self.fc(out)\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        if use_gpu:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "        return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T03:44:08.617700Z",
          "start_time": "2020-05-22T03:44:08.603699Z"
        },
        "id": "xWPDdxIY614U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_network(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
        "    net.train()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # create training and validation data\n",
        "    val_idx = int(len(data) * (1 - val_frac))\n",
        "    data, val_data = data[:val_idx], data[val_idx:]\n",
        "    \n",
        "    # train on gpu if available\n",
        "    if use_gpu:\n",
        "        net.cuda()\n",
        "    \n",
        "    counter = 0\n",
        "    n_chars = len(net.chars)\n",
        "    for e in range(epochs):\n",
        "        hidden_state = net.init_hidden(batch_size)\n",
        "        \n",
        "        for x, y in get_batches(data, batch_size, seq_length):\n",
        "            counter += 1\n",
        "            \n",
        "            x = one_hot_encode(x, n_chars)\n",
        "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
        "            if use_gpu:\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            \n",
        "            # new copy of hidden_state\n",
        "            hidden_state = tuple([each.data for each in hidden_state])\n",
        "            \n",
        "            net.zero_grad()\n",
        "            \n",
        "            output, hidden_state = net(inputs, hidden_state)\n",
        "            \n",
        "            # calculate loss and perform backpropagation\n",
        "            loss = criterion(output, targets.view(batch_size * seq_length).long())\n",
        "            loss.backward()\n",
        "            # using clip_grad_norm to avoid exploding gradient problem\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "            optimizer.step()\n",
        "            \n",
        "            # stats\n",
        "            if counter % print_every == 0:\n",
        "                val_hidden = net.init_hidden(batch_size)\n",
        "                val_losses = []\n",
        "                \n",
        "                net.eval()\n",
        "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
        "                    x = one_hot_encode(x, n_chars)\n",
        "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "                    \n",
        "                    val_hidden = tuple([each.data for each in val_hidden])\n",
        "                    \n",
        "                    inputs, targets = x, y\n",
        "                    if use_gpu:\n",
        "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "                    \n",
        "                    output, val_hidden = net(inputs, val_hidden)\n",
        "                    val_loss = criterion(output, targets.view(batch_size * seq_length).long())\n",
        "                    val_losses.append(val_loss.item())\n",
        "                \n",
        "                net.train()\n",
        "                \n",
        "                print(\"epoch : {} / {}, \".format(e+1, epochs),\n",
        "                      \"step : {}, \".format(counter),\n",
        "                      \"loss : {0:.3f}, \".format(loss.item()), \n",
        "                      \"validation_loss : {0:.3f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T03:44:09.468673Z",
          "start_time": "2020-05-22T03:44:09.220222Z"
        },
        "id": "4dv_7z26614Z",
        "colab_type": "code",
        "outputId": "32ea170d-315a-4bad-92b0-bb445f6a897d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "n_hidden = 512\n",
        "n_layers = 2\n",
        "\n",
        "net = CharRNN(chars, n_hidden, n_layers)\n",
        "net"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharRNN(\n",
              "  (lstm): LSTM(84, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=512, out_features=84, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T04:27:14.607054Z",
          "start_time": "2020-05-22T03:59:11.680108Z"
        },
        "id": "0R1Dt1CI614f",
        "colab_type": "code",
        "outputId": "e9b3a505-919a-4f8e-dde3-3a3d434355d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "batch_size = 128\n",
        "seq_length = 100\n",
        "n_epochs = 20\n",
        "\n",
        "train_network(net, encode_text, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=100)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 1 / 20,  step : 100,  loss : 3.062,  validation_loss : 3.056\n",
            "epoch : 2 / 20,  step : 200,  loss : 2.351,  validation_loss : 2.294\n",
            "epoch : 3 / 20,  step : 300,  loss : 2.097,  validation_loss : 2.041\n",
            "epoch : 3 / 20,  step : 400,  loss : 1.944,  validation_loss : 1.873\n",
            "epoch : 4 / 20,  step : 500,  loss : 1.787,  validation_loss : 1.749\n",
            "epoch : 5 / 20,  step : 600,  loss : 1.698,  validation_loss : 1.652\n",
            "epoch : 5 / 20,  step : 700,  loss : 1.650,  validation_loss : 1.577\n",
            "epoch : 6 / 20,  step : 800,  loss : 1.576,  validation_loss : 1.524\n",
            "epoch : 7 / 20,  step : 900,  loss : 1.507,  validation_loss : 1.478\n",
            "epoch : 8 / 20,  step : 1000,  loss : 1.464,  validation_loss : 1.444\n",
            "epoch : 8 / 20,  step : 1100,  loss : 1.461,  validation_loss : 1.409\n",
            "epoch : 9 / 20,  step : 1200,  loss : 1.422,  validation_loss : 1.384\n",
            "epoch : 10 / 20,  step : 1300,  loss : 1.383,  validation_loss : 1.365\n",
            "epoch : 10 / 20,  step : 1400,  loss : 1.377,  validation_loss : 1.346\n",
            "epoch : 11 / 20,  step : 1500,  loss : 1.327,  validation_loss : 1.323\n",
            "epoch : 12 / 20,  step : 1600,  loss : 1.353,  validation_loss : 1.311\n",
            "epoch : 12 / 20,  step : 1700,  loss : 1.333,  validation_loss : 1.295\n",
            "epoch : 13 / 20,  step : 1800,  loss : 1.284,  validation_loss : 1.283\n",
            "epoch : 14 / 20,  step : 1900,  loss : 1.263,  validation_loss : 1.273\n",
            "epoch : 15 / 20,  step : 2000,  loss : 1.272,  validation_loss : 1.265\n",
            "epoch : 15 / 20,  step : 2100,  loss : 1.237,  validation_loss : 1.256\n",
            "epoch : 16 / 20,  step : 2200,  loss : 1.233,  validation_loss : 1.248\n",
            "epoch : 17 / 20,  step : 2300,  loss : 1.218,  validation_loss : 1.244\n",
            "epoch : 17 / 20,  step : 2400,  loss : 1.219,  validation_loss : 1.240\n",
            "epoch : 18 / 20,  step : 2500,  loss : 1.205,  validation_loss : 1.235\n",
            "epoch : 19 / 20,  step : 2600,  loss : 1.192,  validation_loss : 1.226\n",
            "epoch : 20 / 20,  step : 2700,  loss : 1.198,  validation_loss : 1.224\n",
            "epoch : 20 / 20,  step : 2800,  loss : 1.152,  validation_loss : 1.217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccVhkAy4614l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}