{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "character_level_lstm.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T01:59:25.386005Z",
          "start_time": "2020-05-22T01:59:18.373566Z"
        },
        "id": "HADi30UP6125",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD7sKy60613D",
        "colab_type": "text"
      },
      "source": [
        "### Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:00:22.720047Z",
          "start_time": "2020-05-22T02:00:22.715011Z"
        },
        "id": "glKxaSIE613E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/anna_karenina.txt\", \"rb\") as obj:\n",
        "    text = obj.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:00:32.672315Z",
          "start_time": "2020-05-22T02:00:32.663314Z"
        },
        "id": "KA4malij613K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "798fadc4-66cd-49a0-b6e6-51e07a6f8195"
      },
      "source": [
        "text[:100]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Chapter 1\\r\\n\\r\\n\\r\\nHappy families are all alike; every unhappy family is unhappy in its own\\r\\nway.\\r\\n\\r\\nEve'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USBqfTcK613Q",
        "colab_type": "text"
      },
      "source": [
        "### Tokenization\n",
        "Creating two dictionaries:\n",
        "1. int2char -> maps integers to the characters\n",
        "2. char2int -> maps characters to unique integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:08:40.031153Z",
          "start_time": "2020-05-22T02:08:40.000142Z"
        },
        "id": "HKG4dwGT613R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "013e65e4-52f4-421b-b831-c45a5b032a73"
      },
      "source": [
        "chars = tuple(set(text))\n",
        "print(chars)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 13, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:08:51.831728Z",
          "start_time": "2020-05-22T02:08:51.827728Z"
        },
        "id": "sEjgplDB613X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b7d93edd-fb47-4c67-dffa-d8e2b4f856bd"
      },
      "source": [
        "int2char = dict(enumerate(chars))\n",
        "print(int2char)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 10, 1: 13, 2: 32, 3: 33, 4: 34, 5: 36, 6: 37, 7: 38, 8: 39, 9: 40, 10: 41, 11: 42, 12: 44, 13: 45, 14: 46, 15: 47, 16: 48, 17: 49, 18: 50, 19: 51, 20: 52, 21: 53, 22: 54, 23: 55, 24: 56, 25: 57, 26: 58, 27: 59, 28: 63, 29: 64, 30: 65, 31: 66, 32: 67, 33: 68, 34: 69, 35: 70, 36: 71, 37: 72, 38: 73, 39: 74, 40: 75, 41: 76, 42: 77, 43: 78, 44: 79, 45: 80, 46: 81, 47: 82, 48: 83, 49: 84, 50: 85, 51: 86, 52: 87, 53: 88, 54: 89, 55: 90, 56: 95, 57: 96, 58: 97, 59: 98, 60: 99, 61: 100, 62: 101, 63: 102, 64: 103, 65: 104, 66: 105, 67: 106, 68: 107, 69: 108, 70: 109, 71: 110, 72: 111, 73: 112, 74: 113, 75: 114, 76: 115, 77: 116, 78: 117, 79: 118, 80: 119, 81: 120, 82: 121, 83: 122}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:09:38.257668Z",
          "start_time": "2020-05-22T02:09:38.253700Z"
        },
        "id": "uJ3ZOBN8613h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "002e5c35-20e6-43e7-be72-fb0038597a85"
      },
      "source": [
        "char2int = {ch: count for count, ch in int2char.items()}\n",
        "print(char2int)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{10: 0, 13: 1, 32: 2, 33: 3, 34: 4, 36: 5, 37: 6, 38: 7, 39: 8, 40: 9, 41: 10, 42: 11, 44: 12, 45: 13, 46: 14, 47: 15, 48: 16, 49: 17, 50: 18, 51: 19, 52: 20, 53: 21, 54: 22, 55: 23, 56: 24, 57: 25, 58: 26, 59: 27, 63: 28, 64: 29, 65: 30, 66: 31, 67: 32, 68: 33, 69: 34, 70: 35, 71: 36, 72: 37, 73: 38, 74: 39, 75: 40, 76: 41, 77: 42, 78: 43, 79: 44, 80: 45, 81: 46, 82: 47, 83: 48, 84: 49, 85: 50, 86: 51, 87: 52, 88: 53, 89: 54, 90: 55, 95: 56, 96: 57, 97: 58, 98: 59, 99: 60, 100: 61, 101: 62, 102: 63, 103: 64, 104: 65, 105: 66, 106: 67, 107: 68, 108: 69, 109: 70, 110: 71, 111: 72, 112: 73, 113: 74, 114: 75, 115: 76, 116: 77, 117: 78, 118: 79, 119: 80, 120: 81, 121: 82, 122: 83}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:10:11.019914Z",
          "start_time": "2020-05-22T02:10:10.707877Z"
        },
        "id": "PUZxO1j1613n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "17aaaac1-0538-4af1-8593-7bc91e1f5c60"
      },
      "source": [
        "encode_text = np.array([char2int[ch] for ch in text])\n",
        "encode_text[:100]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([32, 65, 58, 73, 77, 62, 75,  2, 17,  1,  0,  1,  0,  1,  0, 37, 58,\n",
              "       73, 73, 82,  2, 63, 58, 70, 66, 69, 66, 62, 76,  2, 58, 75, 62,  2,\n",
              "       58, 69, 69,  2, 58, 69, 66, 68, 62, 27,  2, 62, 79, 62, 75, 82,  2,\n",
              "       78, 71, 65, 58, 73, 73, 82,  2, 63, 58, 70, 66, 69, 82,  2, 66, 76,\n",
              "        2, 78, 71, 65, 58, 73, 73, 82,  2, 66, 71,  2, 66, 77, 76,  2, 72,\n",
              "       80, 71,  1,  0, 80, 58, 82, 14,  1,  0,  1,  0, 34, 79, 62])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUGHBOic613v",
        "colab_type": "text"
      },
      "source": [
        "### Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:15:28.529108Z",
          "start_time": "2020-05-22T02:15:28.524108Z"
        },
        "id": "s0Axk00f613w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_encode(arr, n_labels):\n",
        "    # initialize the encoded array\n",
        "    one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
        "    # fill appropriate elements with one\n",
        "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
        "    # reshape back to original array\n",
        "    one_hot = one_hot.reshape(*arr.shape, n_labels)\n",
        "    \n",
        "    return one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:16:56.361909Z",
          "start_time": "2020-05-22T02:16:56.355912Z"
        },
        "id": "5iKbABcI6131",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4c20edc2-0e0b-461a-f59b-5e90ae432664"
      },
      "source": [
        "# test_case\n",
        "\n",
        "test_seq = np.array([1, 2, 3, 4, 5])\n",
        "one_hot = one_hot_encode(test_seq, 10)\n",
        "print(one_hot)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:53:57.304384Z",
          "start_time": "2020-05-22T02:53:57.297391Z"
        },
        "id": "goG6WVxh6136",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(arr, batch_size, seq_length):\n",
        "    batch_size_total = batch_size * seq_length\n",
        "    n_batches = len(arr) // batch_size_total\n",
        "    \n",
        "    arr = arr[:n_batches*batch_size_total]\n",
        "    arr = arr.reshape(batch_size, -1)\n",
        "    \n",
        "    for n in range(0, arr.shape[1], seq_length):\n",
        "        x = arr[:, n:n+seq_length]\n",
        "        y = np.zeros_like(x)\n",
        "        try:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
        "        except IndexError:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
        "        yield x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T02:57:04.942457Z",
          "start_time": "2020-05-22T02:57:04.936451Z"
        },
        "id": "2qzvSy1z614A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "686bb3ea-b446-4486-bc0c-6aecc91097f4"
      },
      "source": [
        "# test_case\n",
        "\n",
        "batches = get_batches(encode_text, 8, 50)\n",
        "x, y = next(batches)\n",
        "\n",
        "print(\"x = \\n\", x[:10, :10], \"\\n\")\n",
        "print(\"y = \\n\", y[:10, :10])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x = \n",
            " [[32 65 58 73 77 62 75  2 17  1]\n",
            " [ 0 77 65 72 78 64 65 77 76  2]\n",
            " [78 71 64  2 70 58 71 28  4  1]\n",
            " [71 61  2 77 72  2 75 62 77 66]\n",
            " [75 12  2 65 62  2 65 58 61  2]\n",
            " [72  2 61 66 76 60 78 76 76 66]\n",
            " [ 2 33 72 69 69 82 12  2 61 58]\n",
            " [66 71  2 77 65 62  2 60 72 71]] \n",
            "\n",
            "y = \n",
            " [[65 58 73 77 62 75  2 17  1  0]\n",
            " [77 65 72 78 64 65 77 76  2 72]\n",
            " [71 64  2 70 58 71 28  4  1  0]\n",
            " [61  2 77 72  2 75 62 77 66 75]\n",
            " [12  2 65 62  2 65 58 61  2 71]\n",
            " [ 2 61 66 76 60 78 76 76 66 72]\n",
            " [33 72 69 69 82 12  2 61 58 75]\n",
            " [71  2 77 65 62  2 60 72 71 60]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJv1scNA614H",
        "colab_type": "text"
      },
      "source": [
        "### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T03:03:05.619217Z",
          "start_time": "2020-05-22T03:03:05.616215Z"
        },
        "id": "hKkSkBNm614I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f05b330-a374-40c0-faa3-d80087f5082a"
      },
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    print(\"Training on GPU.\")\n",
        "else:\n",
        "    print(\"Using CPU.\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T03:44:08.279870Z",
          "start_time": "2020-05-22T03:44:08.269869Z"
        },
        "id": "zQLOKk7L614P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, tokens, n_hidden=256, n_layers=2, drop_prob=0.5, lr=0.001):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        self.lr = lr\n",
        "        # creating character dictionaries\n",
        "        self.chars = tokens\n",
        "        self.int2char = dict(enumerate(self.chars))\n",
        "        self.char2int = {ch: count for count, ch in self.int2char.items()}\n",
        "        # define LSTM\n",
        "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, dropout=drop_prob, batch_first=True)\n",
        "        # define dropout layer\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        # define final, fully-connected output layer\n",
        "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        r_out, hidden = self.lstm(x, hidden)\n",
        "        out = self.dropout(r_out)\n",
        "        # stack up LSTM outputs\n",
        "        out = out.contiguous().view(-1, self.n_hidden)\n",
        "        out = self.fc(out)\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        if use_gpu:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "        return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T03:44:08.617700Z",
          "start_time": "2020-05-22T03:44:08.603699Z"
        },
        "id": "xWPDdxIY614U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_network(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
        "    net.train()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # create training and validation data\n",
        "    val_idx = int(len(data) * (1 - val_frac))\n",
        "    data, val_data = data[:val_idx], data[val_idx:]\n",
        "    \n",
        "    # train on gpu if available\n",
        "    if use_gpu:\n",
        "        net.cuda()\n",
        "    \n",
        "    counter = 0\n",
        "    n_chars = len(net.chars)\n",
        "    for e in range(epochs):\n",
        "        hidden_state = net.init_hidden(batch_size)\n",
        "        \n",
        "        for x, y in get_batches(data, batch_size, seq_length):\n",
        "            counter += 1\n",
        "            \n",
        "            x = one_hot_encode(x, n_chars)\n",
        "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
        "            if use_gpu:\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            \n",
        "            # new copy of hidden_state\n",
        "            hidden_state = tuple([each.data for each in hidden_state])\n",
        "            \n",
        "            net.zero_grad()\n",
        "            \n",
        "            output, hidden_state = net(inputs, hidden_state)\n",
        "            \n",
        "            # calculate loss and perform backpropagation\n",
        "            loss = criterion(output, targets.view(batch_size * seq_length).long())\n",
        "            loss.backward()\n",
        "            # using clip_grad_norm to avoid exploding gradient problem\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "            optimizer.step()\n",
        "            \n",
        "            # stats\n",
        "            if counter % print_every == 0:\n",
        "                val_hidden = net.init_hidden(batch_size)\n",
        "                val_losses = []\n",
        "                \n",
        "                net.eval()\n",
        "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
        "                    x = one_hot_encode(x, n_chars)\n",
        "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "                    \n",
        "                    val_hidden = tuple([each.data for each in val_hidden])\n",
        "                    \n",
        "                    inputs, targets = x, y\n",
        "                    if use_gpu:\n",
        "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "                    \n",
        "                    output, val_hidden = net(inputs, val_hidden)\n",
        "                    val_loss = criterion(output, targets.view(batch_size * seq_length).long())\n",
        "                    val_losses.append(val_loss.item())\n",
        "                \n",
        "                net.train()\n",
        "                \n",
        "                print(\"{}\\n\".format(\"-\" * 50),\n",
        "                      \"Epoch : {} / {}\\n\".format(e+1, epochs),\n",
        "                      \"Step : {}\\n\".format(counter),\n",
        "                      \"Loss : {}\\n\".format(loss.item()), \n",
        "                      \"Validation Loss : {}\\n\".format(np.mean(val_losses)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T03:44:09.468673Z",
          "start_time": "2020-05-22T03:44:09.220222Z"
        },
        "id": "4dv_7z26614Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ac6ff599-75de-45ce-bc42-bae0e8ec777e"
      },
      "source": [
        "n_hidden = 512\n",
        "n_layers = 2\n",
        "\n",
        "net = CharRNN(chars, n_hidden, n_layers)\n",
        "net"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharRNN(\n",
              "  (lstm): LSTM(84, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=512, out_features=84, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-22T04:27:14.607054Z",
          "start_time": "2020-05-22T03:59:11.680108Z"
        },
        "id": "0R1Dt1CI614f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79a590db-f8da-4a8f-d205-9855432b9aab"
      },
      "source": [
        "batch_size = 128\n",
        "seq_length = 100\n",
        "n_epochs = 20\n",
        "\n",
        "train_network(net, encode_text, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=100)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            " Epoch : 1 / 20\n",
            " Step : 100\n",
            " Loss : 3.090757131576538\n",
            " Validation Loss : 3.092260233561198\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 2 / 20\n",
            " Step : 200\n",
            " Loss : 2.3579373359680176\n",
            " Validation Loss : 2.2970413684844972\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 3 / 20\n",
            " Step : 300\n",
            " Loss : 2.0954337120056152\n",
            " Validation Loss : 2.037158743540446\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 3 / 20\n",
            " Step : 400\n",
            " Loss : 1.9307934045791626\n",
            " Validation Loss : 1.8639811992645263\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 4 / 20\n",
            " Step : 500\n",
            " Loss : 1.7749394178390503\n",
            " Validation Loss : 1.743209679921468\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 5 / 20\n",
            " Step : 600\n",
            " Loss : 1.6972869634628296\n",
            " Validation Loss : 1.6402958154678344\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 5 / 20\n",
            " Step : 700\n",
            " Loss : 1.6398272514343262\n",
            " Validation Loss : 1.5673156340916952\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 6 / 20\n",
            " Step : 800\n",
            " Loss : 1.573695182800293\n",
            " Validation Loss : 1.5111616134643555\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 7 / 20\n",
            " Step : 900\n",
            " Loss : 1.492079734802246\n",
            " Validation Loss : 1.471703871091207\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 8 / 20\n",
            " Step : 1000\n",
            " Loss : 1.4515498876571655\n",
            " Validation Loss : 1.4341464042663574\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 8 / 20\n",
            " Step : 1100\n",
            " Loss : 1.4528461694717407\n",
            " Validation Loss : 1.403336238861084\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 9 / 20\n",
            " Step : 1200\n",
            " Loss : 1.4080387353897095\n",
            " Validation Loss : 1.3831957578659058\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 10 / 20\n",
            " Step : 1300\n",
            " Loss : 1.3752583265304565\n",
            " Validation Loss : 1.3559804995854696\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 10 / 20\n",
            " Step : 1400\n",
            " Loss : 1.382821798324585\n",
            " Validation Loss : 1.336324644088745\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 11 / 20\n",
            " Step : 1500\n",
            " Loss : 1.3268200159072876\n",
            " Validation Loss : 1.3222840229670207\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 12 / 20\n",
            " Step : 1600\n",
            " Loss : 1.353836178779602\n",
            " Validation Loss : 1.3102127313613892\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 12 / 20\n",
            " Step : 1700\n",
            " Loss : 1.3381831645965576\n",
            " Validation Loss : 1.2923964818318685\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 13 / 20\n",
            " Step : 1800\n",
            " Loss : 1.2803711891174316\n",
            " Validation Loss : 1.2809999465942383\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 14 / 20\n",
            " Step : 1900\n",
            " Loss : 1.2705509662628174\n",
            " Validation Loss : 1.2762431939442953\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 15 / 20\n",
            " Step : 2000\n",
            " Loss : 1.2753368616104126\n",
            " Validation Loss : 1.2674528280893962\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 15 / 20\n",
            " Step : 2100\n",
            " Loss : 1.2274585962295532\n",
            " Validation Loss : 1.2510203917821248\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 16 / 20\n",
            " Step : 2200\n",
            " Loss : 1.2314162254333496\n",
            " Validation Loss : 1.2442243258158365\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 17 / 20\n",
            " Step : 2300\n",
            " Loss : 1.2314414978027344\n",
            " Validation Loss : 1.2386040687561035\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 17 / 20\n",
            " Step : 2400\n",
            " Loss : 1.2085596323013306\n",
            " Validation Loss : 1.2350413163503011\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 18 / 20\n",
            " Step : 2500\n",
            " Loss : 1.1991677284240723\n",
            " Validation Loss : 1.2292783339818318\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 19 / 20\n",
            " Step : 2600\n",
            " Loss : 1.1955981254577637\n",
            " Validation Loss : 1.2249891678492228\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 20 / 20\n",
            " Step : 2700\n",
            " Loss : 1.1964943408966064\n",
            " Validation Loss : 1.2162331104278565\n",
            "\n",
            "--------------------------------------------------\n",
            " Epoch : 20 / 20\n",
            " Step : 2800\n",
            " Loss : 1.1538549661636353\n",
            " Validation Loss : 1.212931791941325\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccVhkAy4614l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}